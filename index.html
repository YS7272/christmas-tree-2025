<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <title>ðŸŽ„ Christmas Magic</title>
    
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link href="https://fonts.googleapis.com/css2?family=Cinzel:wght@400;700&display=swap" rel="stylesheet">

    <style>
        :root { --c-bg: #000000; --c-gold: #d4af37; }
        body { margin: 0; background-color: var(--c-bg); overflow: hidden; font-family: 'Cinzel', serif; user-select: none; -webkit-tap-highlight-color: transparent; }

        /* UI Overlay */
        #ui-layer { position: absolute; inset: 0; pointer-events: none; z-index: 10; opacity: 0; transition: opacity 1s; }
        .visible { opacity: 1 !important; }

        /* Start Screen */
        #start-screen {
            position: fixed; top: 0; left: 0; width: 100%; height: 100%;
            background: radial-gradient(circle, #1a0b2e 0%, #000000 100%);
            z-index: 999;
            display: flex; flex-direction: column; justify-content: center; align-items: center;
            transition: opacity 0.8s;
        }

        .magic-btn {
            padding: 15px 40px;
            background: rgba(212, 175, 55, 0.1);
            border: 1px solid #d4af37;
            color: #d4af37;
            font-size: 18px;
            letter-spacing: 2px;
            border-radius: 50px;
            cursor: pointer;
            animation: pulse 2s infinite;
            text-transform: uppercase;
            margin-top: 30px;
        }
        @keyframes pulse { 0% { box-shadow: 0 0 0 0 rgba(212, 175, 55, 0.4); } 70% { box-shadow: 0 0 0 20px rgba(212, 175, 55, 0); } 100% { box-shadow: 0 0 0 0 rgba(212, 175, 55, 0); } }

        h1 { color: #fff; text-shadow: 0 0 20px gold; font-size: 28px; text-align: center; }
        
        /* Loading Status */
        #loading-text { color: #666; font-size: 12px; margin-top: 10px; }

        /* Controls */
        .controls-wrapper { position: absolute; bottom: 10%; width: 100%; text-align: center; pointer-events: auto; }
        .glass-btn {
            padding: 12px 30px; background: rgba(255, 255, 255, 0.1);
            border: 1px solid rgba(255, 255, 255, 0.3); color: #fff;
            border-radius: 30px; cursor: pointer; backdrop-filter: blur(5px);
        }
        input[type="file"] { display: none; }
        
        #webcam { position: fixed; bottom: 10px; right: 10px; width: 100px; opacity: 0.6; pointer-events: none; border-radius: 8px; transform: scaleX(-1); }
    </style>

    <script type="importmap">
        {
            "imports": {
                "three": "https://cdn.jsdelivr.net/npm/three@0.160.0/build/three.module.js",
                "three/addons/": "https://cdn.jsdelivr.net/npm/three@0.160.0/examples/jsm/",
                "@mediapipe/tasks-vision": "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3/+esm"
            }
        }
    </script>
</head>
<body>

    <!-- 
        AUDIO SOURCE: LOCAL FILE
        IMPORTANT: You must upload a file named 'music.mp3' to your GitHub repository!
    -->
    <audio id="bgm" loop preload="auto">
        <source src="./music.mp3" type="audio/mpeg">
    </audio>

    <!-- Start Screen -->
    <div id="start-screen">
        <h1>MERRY CHRISTMAS</h1>
        <div style="color: #ccc; font-size: 14px;">High Quality Audio Edition</div>
        <div id="loading-text">Ready to play</div>
        <div class="magic-btn" id="start-btn">TAP TO START</div>
    </div>

    <!-- UI Layer -->
    <div id="ui-layer">
        <header>
            <h1>Merry Christmas</h1>
        </header>
        <div class="controls-wrapper">
            <label class="glass-btn">
                ðŸ“· Upload Photo
                <input type="file" id="imageInput" accept="image/*">
            </label>
            <div style="font-size: 10px; color: rgba(255,255,255,0.5); margin-top: 15px;">
                [H] Hide UI | Pinch: Focus | Fist: Tree | Open: Scatter
            </div>
        </div>
    </div>

    <video id="webcam" autoplay playsinline muted></video>

    <script type="module">
        import * as THREE from 'three';
        import { RoomEnvironment } from 'three/addons/environments/RoomEnvironment.js';
        import { EffectComposer } from 'three/addons/postprocessing/EffectComposer.js';
        import { RenderPass } from 'three/addons/postprocessing/RenderPass.js';
        import { UnrealBloomPass } from 'three/addons/postprocessing/UnrealBloomPass.js';
        import { FilesetResolver, HandLandmarker } from '@mediapipe/tasks-vision';

        // --- GLOBAL STATE ---
        const STATE = { mode: 'TREE', targetPhoto: null, handRotation: { x: 0, y: 0 }, photos: [] };
        const audio = document.getElementById('bgm');
        const startBtn = document.getElementById('start-btn');
        const statusText = document.getElementById('loading-text');

        // --- AUDIO HANDLING ---
        // 1. Pre-check if file exists
        audio.onerror = () => {
            statusText.innerText = "Error: 'music.mp3' not found in repository!";
            statusText.style.color = "red";
        };

        // 2. Unlock Audio on Click
        startBtn.addEventListener('click', () => {
            // Remove UI
            const screen = document.getElementById('start-screen');
            screen.style.opacity = 0;
            setTimeout(() => screen.remove(), 800);
            document.getElementById('ui-layer').classList.add('visible');

            // Play Audio
            audio.volume = 0.8;
            const playPromise = audio.play();
            
            if (playPromise !== undefined) {
                playPromise.then(_ => {
                    console.log("Audio started!");
                }).catch(error => {
                    console.log("Audio play failed, retrying on interaction.");
                });
            }

            initApp();
        });

        // --- 3D SCENE ---
        const scene = new THREE.Scene();
        scene.fog = new THREE.FogExp2(0x000000, 0.02);
        const camera = new THREE.PerspectiveCamera(50, window.innerWidth/window.innerHeight, 0.1, 200);
        camera.position.set(0, 2, 60);

        const renderer = new THREE.WebGLRenderer({ antialias: true, alpha: true });
        renderer.setSize(window.innerWidth, window.innerHeight);
        renderer.setPixelRatio(Math.min(window.devicePixelRatio, 2));
        renderer.toneMapping = THREE.ACESFilmicToneMapping;
        document.body.appendChild(renderer.domElement);

        const composer = new EffectComposer(renderer);
        composer.addPass(new RenderPass(scene, camera));
        const bloom = new UnrealBloomPass(new THREE.Vector2(window.innerWidth, window.innerHeight), 1.5, 0.4, 0.85);
        bloom.strength = 1.2; bloom.radius = 0.5; bloom.threshold = 0.2;
        composer.addPass(bloom);

        const pmremGenerator = new THREE.PMREMGenerator(renderer);
        scene.environment = pmremGenerator.fromScene(new RoomEnvironment(), 0.04).texture;
        scene.add(new THREE.AmbientLight(0xffffff, 0.4));
        scene.add(new THREE.PointLight(0xd4af37, 2, 60));

        // --- PARTICLES ---
        const mainGroup = new THREE.Group();
        scene.add(mainGroup);
        const particles = [];
        const geoSphere = new THREE.SphereGeometry(0.4, 16, 16);
        const geoBox = new THREE.BoxGeometry(0.6, 0.6, 0.6);
        const matGold = new THREE.MeshStandardMaterial({ color: 0xd4af37, roughness: 0.1, metalness: 1.0 });
        const matRed = new THREE.MeshPhysicalMaterial({ color: 0x8a0b0b, roughness: 0.2, metalness: 0.1 });

        function initParticles() {
            const count = window.innerWidth < 768 ? 1000 : 1600; 
            for(let i=0; i<count; i++) {
                const mesh = new THREE.Mesh(Math.random()>0.5 ? geoSphere : geoBox, Math.random()>0.4 ? matGold : matRed);
                mesh.position.set((Math.random()-0.5)*100, (Math.random()-0.5)*100, (Math.random()-0.5)*100);
                mainGroup.add(mesh);
                particles.push({ mesh, i, total: count, target: new THREE.Vector3() });
            }
        }

        // --- SNOW ---
        const snowGeo = new THREE.BufferGeometry();
        const snowPos = [];
        for(let i=0; i<1500; i++) snowPos.push((Math.random()-0.5)*200, (Math.random()-0.5)*200, (Math.random()-0.5)*200);
        snowGeo.setAttribute('position', new THREE.Float32BufferAttribute(snowPos, 3));
        const snowSys = new THREE.Points(snowGeo, new THREE.PointsMaterial({color: 0xffffff, size: 0.4, transparent:true, opacity:0.6}));
        scene.add(snowSys);

        // --- PHOTO ---
        function createPhotoFrame(tex) {
            tex.colorSpace = THREE.SRGBColorSpace;
            const g = new THREE.Group();
            const frame = new THREE.Mesh(new THREE.BoxGeometry(2.2, 2.7, 0.1), matGold);
            const pic = new THREE.Mesh(new THREE.PlaneGeometry(2, 2.5), new THREE.MeshBasicMaterial({map: tex}));
            pic.position.z = 0.06;
            g.add(frame); g.add(pic);
            mainGroup.add(g);
            const idx = Math.floor(Math.random()*particles.length);
            const p = particles[idx];
            mainGroup.remove(p.mesh); p.mesh = g; 
            STATE.photos.push(g);
            STATE.mode = 'FOCUS'; STATE.targetPhoto = g;
            setTimeout(() => STATE.mode = 'TREE', 5000);
        }

        document.getElementById('imageInput').addEventListener('change', (e) => {
            if(e.target.files[0]) {
                const r = new FileReader();
                r.onload = (ev) => new THREE.TextureLoader().load(ev.target.result, createPhotoFrame);
                r.readAsDataURL(e.target.files[0]);
            }
        });

        // --- ANIMATION ---
        const clock = new THREE.Clock();
        function animate() {
            requestAnimationFrame(animate);
            const t = clock.getElapsedTime();

            mainGroup.rotation.y += 0.002 + (STATE.handRotation.x - mainGroup.rotation.y) * 0.05;
            mainGroup.rotation.x += (STATE.handRotation.y - mainGroup.rotation.x) * 0.05;
            snowSys.rotation.y = t * 0.05; snowSys.position.y = -(t*2)%10;

            particles.forEach(p => {
                if(STATE.mode === 'TREE') {
                    const prog = p.i / p.total;
                    const y = -22 + prog * 50;
                    const r = 18 * (1 - prog);
                    const a = p.i * 0.5 + t * 0.1;
                    p.target.set(Math.cos(a)*r, y, Math.sin(a)*r);
                } else if(STATE.mode === 'SCATTER') {
                    const r = 30; const a = p.i * 0.1 + t * 0.1;
                    p.target.set(Math.cos(a)*r, (Math.sin(p.i)*30), Math.sin(a)*r);
                } else if(STATE.mode === 'FOCUS') {
                    if(STATE.photos.includes(p.mesh) && p.mesh === STATE.targetPhoto) {
                        p.target.set(0,0,40); p.mesh.lookAt(0,0,70); p.mesh.scale.setScalar(2);
                    } else {
                        const r = 40; const a = p.i * 0.2;
                        p.target.set(Math.cos(a)*r, (Math.random()-0.5)*80, Math.sin(a)*r);
                        p.mesh.scale.setScalar(0.5);
                    }
                }
                p.mesh.position.lerp(p.target, 0.05);
            });
            composer.render();
        }

        function initApp() { initParticles(); initCV(); animate(); }

        // --- CV ---
        async function initCV() {
            try {
                const constraints = { video: { facingMode: "user" } };
                const stream = await navigator.mediaDevices.getUserMedia(constraints);
                const video = document.getElementById('webcam');
                video.srcObject = stream;
                const vision = await FilesetResolver.forVisionTasks("https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3/wasm");
                const landmarker = await HandLandmarker.createFromOptions(vision, {
                    baseOptions: { modelAssetPath: `https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task`, delegate: "GPU" },
                    runningMode: "VIDEO", numHands: 1
                });
                video.addEventListener("loadeddata", () => {
                    const predict = () => {
                        if(video.currentTime>0) {
                            const res = landmarker.detectForVideo(video, performance.now());
                            if(res.landmarks[0]) {
                                const l = res.landmarks[0];
                                STATE.handRotation.x = (l[9].x-0.5)*2; STATE.handRotation.y = (l[9].y-0.5)*2;
                                const pinch = Math.hypot(l[4].x-l[8].x, l[4].y-l[8].y);
                                const open = Math.hypot(l[0].x-l[12].x, l[0].y-l[12].y);
                                if(pinch<0.05) {
                                    if(STATE.mode!=='FOCUS') { STATE.mode='FOCUS'; if(STATE.photos.length) STATE.targetPhoto = STATE.photos[Math.floor(Math.random()*STATE.photos.length)]; }
                                } else if(open<0.25) STATE.mode='TREE';
                                else if(open>0.4) STATE.mode='SCATTER';
                            }
                        }
                        requestAnimationFrame(predict);
                    };
                    predict();
                });
            } catch(e) { console.log("CV disabled"); }
        }
        window.addEventListener('resize', () => {
            camera.aspect = window.innerWidth/window.innerHeight; camera.updateProjectionMatrix();
            renderer.setSize(window.innerWidth, window.innerHeight); composer.setSize(window.innerWidth, window.innerHeight);
        });
    </script>
</body>
</html>